Decisions: The file format uses 8-bit/1-byte alignment. Higher-order alignment is not considered, as we favor small file size. For temporary data and algorithms, higher-order alignment should be used.
0.5 Document Mission Statment, 
1. Build a project using bcsv with C++ and Python interfaces
    - demonstrate MatPlotLib
2. create CLI tools:
    - bcsv2csv add arguments --firstRow --lastRow and --slice to allows the selection of a region for converting data, use python slicing syntax
    - bcsvHead print a section at the start of the file, using comma seperated values (incl. header)
    - bcsvTail print a section at the end of the file, using comma separated values (no header)
    - bcsvHeader: Prints the header in a human readable version (vertical list format), provide column, name and type.
3. Improve compression:
    - Implement dictionary compression for strings
    - Implement ZigZag and variable-length integer encoding (also apply to string addresses, row length, and length)
    - Implement CHIMP/GORILLA compression for floats
4. Create random access / random read methods:
    Row row(size_t index) {
        if(index == current_index+1) {
            //fall back to sequential
            readNext();
            return row_;
        }
        //check if row is in current packet, if not read packet required, build an file wide index if needed
        // use specific heuristics for ZoH, i.e. traverse several rows back and for to avoid complex reads
    }
    const auto& cell(size_t rowIndex, size_t colIndex) // To directly access a cell, use RowView as a lightweight abstraction to avoid full deserialization
5. Create sampler (select data based on certain conditions)
    - Support C++ interface (iterate over individual rows)
    - Support Python interface (iterate over individual rows and block reads (pandas/numpy))
6. Add other data types (float8_t, float16_t, float_123_t, uint128_t, int128_t, BLOB)
7. Add concurrent compression and writing using double buffering to avoid blocking the row interface when a packet needs to be written or read
8. Investigate stream write/stream read to avoid utilization spikes that come with packet-based format
9. Create three different bcsv file formats:
    - Packet-based format: good compromise on size, sequential and random access speeds. Building packets may cause some jitter/spikes in utilization, which may be an issue for hard real-time systems. Compatible with all compression and encoding schemes.
    - Indexed file format: for maximum random access speeds and highest compression levels.
    - Stream file format: for hard real-time systems, not compatible with LZ4 compression. Aimed at sequential write & read with limited compute requirements.
10. CLI tools:
    - bcsv2Parquet
    - parquet2bcsv
    - bcsvIndex (creates an indexed file for faster random access)
    - bcsvSampler (creates an down sampled version, using specific rules provided)
13. ROS integration (subscribe ROS topics and store to bcsv and reverse)
14. MQTT integration (read MQTT topics and store to bcsv and reverse)
15. Dynamic BitSet, ensure wide types (uin64/32/16 are used if possible), also consider SIMD/AVX
16. Add SIMD / vectorized interfaces:
    - Python: implement get/set functions for numpy
    - C#/Unity: compatibility with componet/job system
17. Improve compression:
    - Implement first and second order hold schemes (mark candidates in layout/header)
